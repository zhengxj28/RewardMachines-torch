testing_params:
  test: true
  test_freq: 1000
  num_steps: 1000

learning_params:
  total_units: 1000
  step_unit: 1000
  lr: 0.0003
  gamma: 0.99
  buffer_size: 1000000
  train_freq: 1
  batch_size: 256
  target_network_update_freq: 1  # softly update each step
  learning_starts: 25000  # 25000

  # sac do not need normalization tricks
  use_state_norm: false
  use_reward_norm: false
  use_reward_scaling: false

  # sac params
  tau: 0.005  # softly update target network
  fix_alpha: true

model_params:
  action_bound: 1.0
  num_hidden_layers: 3
  num_neurons: 256
  activation: "relu"
  orthogonal_init: false



