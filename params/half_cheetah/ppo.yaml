testing_params:
  test: true
  test_freq: 1000 # should be equals to step_unit
  num_steps: 1000 # max length of an episode

learning_params:
  tabular_case: false
  total_units: 1000
  step_unit: 1000
  lr: 0.0003
  gamma: 0.99
  buffer_size: 2048 # as long as >=num_steps
  batch_size: 64  # mini-batch, 32 or 64

  # ppo params
  clip_rate: 0.2
  lam: 0.95
  n_updates: 10
  policy_loss_coef: 1.0
  value_loss_coef: 1.0
  entropy_loss_coef: 0.01

  # ppo tricks
  use_adv_norm: true
  use_state_norm: true
  use_reward_norm: true
  use_reward_scaling: false # scaling seems worse than norm
  use_grad_clip: true
  use_lr_decay: true
  adam_eps: 0.00001


model_params:
  std_module: "parameter" # "fixed", "parameter" or "layer"
  init_std: 1.0
  action_bound: 1.0
  tabular_case: false
  num_hidden_layers: 3
  num_neurons: 64
  activation: "tanh"
  orthogonal_init: true

