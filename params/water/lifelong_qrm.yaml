testing_params:
  test: true
  test_freq: 1000  #1000
  num_steps: 600

learning_params:
  total_units: 1500  # 500*4
  step_unit: 1000  # 1000
  lr: 0.00001  # 1e-5
  epsilon: 0.1
  gamma: 0.9
  buffer_size: 50000
  train_freq: 1
  batch_size: 32
  target_network_update_freq: 100  # obs: 500 makes learning more stable, but slower
  learning_starts: 1000
  tabular_case: false
  use_random_maps: false
  transfer_methods: "equivalent"  # "none"/"equivalent"/"value_com"/"distill"
  # only available for transfer_methods=="value_com"
  transfer_normalization: true
  value_com:  # compose methods for operators "and", "or", "then" respectively
    - "average"
    - "max"
    - "left"
  # only available for distill_att=="n_emb"
  ltl_correlation_weight: 100 # 0<=weight<1, the sum weights of correlated policies (Q-values)
  att_lr: 0.001
  w_q_loss_rate: 1.0
  diff_loss_rate: 0
  distill_rate: 1
  adaptive_distill: true

model_params:
  tabular_case: false
  num_hidden_layers: 6
  num_neurons: 64
  distill_att: "n_emb" # "none"/"n_emb"