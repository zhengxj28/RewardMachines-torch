testing_params:
  test: true
  test_freq: 10  #1000
  num_steps: 600

learning_params:
  total_units: 15  # 500*4
  step_unit: 10  # 1000
  lr: 0.00001  # 1e-5
  epsilon: 0.1
  gamma: 0.9
  buffer_size: 50000
  train_freq: 1
  batch_size: 32
  target_network_update_freq: 100  # obs: 500 makes learning more stable, but slower
  learning_starts: 1000
  tabular_case: false
  use_random_maps: false
  transfer_methods: "equivalent"  # "none"/"equivalent"/"value_com"/"distill"
  # only available for transfer_methods=="value_com"
  transfer_normalization: true
  value_com:  # compose methods for operators "and", "or", "then" respectively
    - "average"
    - "max"
    - "left"
  # only available for distill_att=="n_emb"
  ltl_correlation_weight: 100 # weight>=0, the bias before softmax of correlated policies (Q-values)
  att_lr: 0.1
  eval_by_student: true
  # [initial, end], adaptive decrease
  decrease_speed: 10
  distill_coefs:
    - 1
    - 0
  teacher_rates:
    - 1
    - 0

model_params:
  tabular_case: false
  num_hidden_layers: 6
  num_neurons: 64
  distill_att: "n_emb" # "none"/"n_emb"